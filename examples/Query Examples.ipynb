{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDK Examples - Querying Data Models\n",
    "\n",
    "Some of the most common query operators in the Sight Machine SDK. We'll use the demo environment (https://demo.sightmachine.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smsdk import client\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_var_tenant = 'ENV_SDK_VAR_TENANT'\n",
    "env_var_api_key = 'ENV_SDK_VAR_API_KEY'\n",
    "env_var_api_secret = 'ENV_SDK_VAR_API_SECRET'\n",
    "\n",
    "# Check if the environment variable exists\n",
    "if env_var_tenant in os.environ:\n",
    "    # Retrieve the value of the environment variable\n",
    "    tenant = os.environ[env_var_tenant]\n",
    "else:\n",
    "    # Use a default value if the environment variable is not present\n",
    "    tenant = 'demo'\n",
    "\n",
    "# Check if the environment variable exists\n",
    "if env_var_api_key in os.environ:\n",
    "    # Retrieve the value of the environment variable\n",
    "    api_key = os.environ[env_var_api_key]\n",
    "else:\n",
    "    # Use a default value if the environment variable is not present\n",
    "    api_key = ''\n",
    "\n",
    "# Check if the environment variable exists\n",
    "if env_var_api_secret in os.environ:\n",
    "    # Retrieve the value of the environment variable\n",
    "    api_secret = os.environ[env_var_api_secret]\n",
    "else:\n",
    "    # Use a default value if the environment variable is not present\n",
    "    api_secret = ''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the SDK client and get a list of all machine types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli = client.Client(tenant)\n",
    "cli.login('apikey', \n",
    "          key_id = api_key, \n",
    "          secret_id = api_secret)\n",
    "\n",
    "types = cli.get_machine_type_names()\n",
    "types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Cycles\n",
    "\n",
    "Cycles are the core data set in the SM Platform.  Cycles represent a unit of work on a machine and will contain a variety of data from sensors, quality managent systems, ERP, MES, etc.  \n",
    "\n",
    "Each cycle is associate with a Machine and a range of time.  Each Machine has a machine type which determines the data schema.  So to query for cycle data, the first step is to lookup the machine type and then to lookup the specific machine(s) of that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list machines of a specific type\n",
    "machine_type = types[0]\n",
    "machines = cli.get_machine_names(source_type=machine_type)\n",
    "machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the schema for a particular machine (more on this at end of notebook)\n",
    "# extract only a list of tag display names\n",
    "columns = cli.get_machine_schema(machines[0])['display'].to_list()\n",
    "\n",
    "# going to skip the first 8 fields since those are our internal / common fields\n",
    "columns = columns[8:]\n",
    "columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a Particular Development Pipeline schema\n",
    "\n",
    "You can select a development pipeline schema using following code example. This works very similarly to the 'in-use' feature in MA - we can select an alternate pipeline to treat as the production one. Similarly to MA, the setting will persist until you change it back or create a new client.\n",
    "\n",
    "*Note: By default, the production pipeline schema will be used (just like in MA).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_schema = 'pipeline_id' \n",
    "cli.select_db_schema(schema_name=db_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A basic starting query.\n",
    "\n",
    "Once you have a machine type and machine, you can start to query for cycle data.  We'll use variations on this theme to demonstrate different query options and their effects.\n",
    "\n",
    "Note that this baseline query already demonstrates:\n",
    "- Basic filter rules formatted as key value pairs\n",
    "- Filtering for greater than or less than values\n",
    "    - It uses `__gte` for greater than or equal.  Use `__gt` for greater than.  Similarly `__lte` is less than or equal vs. `__lt` for less than.\n",
    "- Sorting returned results\n",
    "    - Note the `-` prefix before `Endtime` means to sort descending.  To sort ascending, do not place a prefix in front of the variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {'Machine': machines[0],\n",
    "         'End Time__gte' : datetime(2023, 4, 1), \n",
    "         'End Time__lte' : datetime(2023, 4, 2), \n",
    "         '_order_by': '-End Time'}\n",
    "df = cli.get_cycles(**query)\n",
    "\n",
    "print(f'Size of returned data: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting columns and silencing the `_only` Warning\n",
    "\n",
    "To select a specific set of columns, provide a list of column names as a value for the key _only.  For example, `'_only': ['column1', 'column2', 'column3']`\n",
    "\n",
    "If you do not use _only, the SDK will automatically select the first 50 stats in the machine's configuration, plus common metadata fields for the query.  \n",
    "\n",
    "Note, you can also pass `'_only': '*'`, which will return everything, including a large number of internal fields.  Since this includes may fields you probably will not need, expect the resulting queries to be quite slow.\n",
    "\n",
    "**IMPORTANT** If a selected column is all null, it will not be included in the returned data frame.  If you are getting fewer columns returned than expected, this mostly likely means that there was only null data for that column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first 10 columns, plus Machine and End Time\n",
    "select_columns = ['Machine', 'End Time'] + columns[:5]\n",
    "\n",
    "query = {'Machine': machines[0],\n",
    "         'End Time__gte' : datetime(2023, 4, 1), \n",
    "         'End Time__lte' : datetime(2023, 4, 2),  \n",
    "         '_order_by': '-End Time',\n",
    "         '_only': select_columns}\n",
    "df = cli.get_cycles(**query)\n",
    "\n",
    "print(f'Size of returned data: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricting the number of rows returned with `_limit` and `_offset`\n",
    "\n",
    "To restrict the number of rows, use the _limit query option.  For example, `'_limit': 500`.  This will then return at most 500 rows.  \n",
    "\n",
    "To skip over a specified number of rows, use the _offset query option.  For example `'_offset': 50`.\n",
    "\n",
    "It is fairly common to use a combination of _limit and _offset togheter for applications such as paginating data.  For example, if a query would normally return 100 rows and you want to break it into two queries you could return the first 50 rows with `'_offset': 0, '_limit': 50` and then return the second 50 rows with `'_offset': 50, '_limit': 50`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {'Machine': machines[0],\n",
    "         'End Time__gte' : datetime(2023, 4, 1), \n",
    "         'End Time__lte' : datetime(2023, 4, 2),  \n",
    "         '_order_by': '-End Time',\n",
    "         '_offset': 10,\n",
    "         '_limit': 500}\n",
    "df = cli.get_cycles(**query)\n",
    "\n",
    "print(f'Size of returned data: {df.shape}')\n",
    "\n",
    "# Notice in the returned data set that the first row is at 23:49 - 23:50 instead of midnight, becuase of the offset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from more than one Machine or filtering by a list of values using `__in`\n",
    "\n",
    "Filters can specify a list of acceptable values.  This is most commonly used when selecting data from more than one machine, though it can be used on any field name.  This is done by appending `__in` (*note two underscores*) to the column name and then specifying the list of options.  For example:\n",
    "\n",
    "    'Machine__in': ['Oven1', 'Oven2']\n",
    "\n",
    "or\n",
    "\n",
    "    'Status__in': ['Idle', 'Maintenance', 'Down']\n",
    "\n",
    "**Important** Selecting multiple machines of different types can result in spare and confusing data frames.  It is strongly recommended to only pick multiple machines of the same type.\n",
    "\n",
    "You can also query for values that are not in a list by using `__nin` with the same format as `__in`.  For example:\n",
    "\n",
    "    'Product_Code__nin': ['SuperMax 5000', 'MegaValue 6000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: taking the first three machines' data, so will result in three times as many records returned\n",
    "query = {'Machine__in': machines[0:3],\n",
    "         'End Time__gte' : datetime(2023, 4, 1), \n",
    "         'End Time__lte' : datetime(2023, 4, 2),  \n",
    "         '_order_by': '-End Time'}\n",
    "df = cli.get_cycles(**query)\n",
    "\n",
    "print(f'Size of returned data: {df.shape}')\n",
    "# Notice the Machine column now has three different values\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering to only rows where a specified field exists with `__exists`\n",
    "\n",
    "Some data fields, such as inspection data, are often quite sparse.  To filter to only rows with or without non-null values, use `__exists`.  `__exists` should be appended to the name of the field, and then give it a boolean for if you want the field to exist (True) or not exist (False).  For example:\n",
    "\n",
    "    'Inspection_Value__exists': True\n",
    "\n",
    "or\n",
    "\n",
    "    'Failure_Code__exists': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = { 'Machine': machines[0],\n",
    "         'stats__Alarms__val__exists': False,\n",
    "         'End Time__gte' : datetime(2023, 4, 1), \n",
    "         'End Time__lte' : datetime(2023, 4, 2), \n",
    "         '_order_by': '-End Time',\n",
    "         '_only': ['Machine', 'End Time', 'Alarms']}\n",
    "df = cli.get_cycles(**query)\n",
    "\n",
    "print(f'Size of returned data: {df.shape}')\n",
    "# Query now only has the small subset of machines\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for inequality with `__ne`\n",
    "\n",
    "The standard `key: value` format assumes it is testing when the key equals the value.  To change this to inequality, add a `__ne` suffix.  For example, `'StatusCode__ne': 0`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {'Machine__in': machines[0:3],\n",
    "         'output__ne': 0,\n",
    "         'End Time__gte' : datetime(2023, 4, 3), \n",
    "         'End Time__lte' : datetime(2023, 4, 6), \n",
    "         '_order_by': '-End Time',\n",
    "         '_only': ['Machine', 'End Time', 'output']}\n",
    "df = cli.get_cycles(**query)\n",
    "\n",
    "print(f'Size of returned data: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Downtimes\n",
    "Similarly to Cycles, the Downtime data model can be queried for a given machine. Everything from the above section still applies, but the main function is get_downtimes() as opposed to get_cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {'Machine': machines[0],\n",
    "         'End Time__gte' : datetime(2023, 4, 1), \n",
    "         'End Time__lte' : datetime(2023, 4, 2), \n",
    "         '_order_by': '-End Time'}\n",
    "df = cli.get_downtimes(**query)\n",
    "\n",
    "print(f'Size of returned data: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Parts\n",
    "\n",
    "Whereas Cycles contain data happening on a particular machine, Parts track an object across multiple machines.  The general structure for query parts is similar for working with cycles, though slightly simpler.  With a Cycle, the pattern is to find the Machine Type, then the Machine, then get Cycle data associated with the machine.  With Parts, you only need a two step process to look up Part Types and then Part data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_types = cli.get_part_type_names()\n",
    "part_type = part_types[0]\n",
    "part_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at parts schema, same as we did above for machine schema\n",
    "columns = cli.get_part_schema(part_type)['display'].to_list()\n",
    "columns[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The options for querying parts are similar to querying for cycles - use the same operators described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {'Part': part_type,\n",
    "         'End Time__gte' : datetime(2023, 4, 1), \n",
    "         'End Time__lte' : datetime(2023, 4, 2),\n",
    "         'DefectReason__exists': True,\n",
    "         '_limit': 10,\n",
    "         '_only': columns[:30]}\n",
    "\n",
    "df = cli.get_parts(**query)\n",
    "\n",
    "print(f'Size of returned data: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machines and Machine Types\n",
    "There is additional information about machines and machine types that can be queried from the SDK. This info can help you format or transform your queries to fit your needs. Examples are included below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine-Level Info\n",
    "\n",
    "### Timezones\n",
    "\n",
    "By default, all timestamps are in UTC.  To find the local timezone associated with a machine, use the ```get_machine_timezone``` function and provide the machine name.  This will then return the name of the timezone, which can be used with libraries such as pytz to convert time zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(machines[0])\n",
    "tz = cli.get_machine_timezone(machines[0])\n",
    "print(tz)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Machine Type from Machine\n",
    "All machines can be grouped into machine types. You may need to programmatically look up the type of a machine given its name. To get the machine type using machine name (or display name), use ```cli.get_type_from_machine(machine_name)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli.get_type_from_machine(machines[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Machine Data Schema\n",
    "The machine schema is a table containing metadata about the tags included in cycle data for a particular machine. It can be retrieved with ```cli.get_machine_schema(machine_name)```. There are a few additional optional parameters that can be passed to the function:\n",
    "- ```types```: list of strings specifying a subset of column data types that you want to see.\n",
    "    - ```cli.get_machine_schema(machine_name, types=['continuous'])```\n",
    "- ```show_hidden```: (default = False) set to True to see the few additional fields that are hidden by default both here and in MA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the schema for a particular machine\n",
    "schema = cli.get_machine_schema(machines[0])\n",
    "schema.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: look at all the various data types for this model\n",
    "print(schema['type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: extract list of tags with numeric data types\n",
    "schema_numeric = schema[schema['type'].apply(lambda x: x in ['int', 'float'])]\n",
    "cols = schema['display'].to_list()\n",
    "cols[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate method\n",
    "schema_str = cli.get_machine_schema(machines[0], types=['continuous'])\n",
    "schema_str.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine-Type-Level Info\n",
    "\n",
    "### Get Machine Type Schema (```get_fields_of_machine_type```)\n",
    "This function is very similar to the above get_machine_schema, except it gets fields that are part of a machine type definition. This function has the same optional parameters as above:\n",
    "- ```types```: list of strings specifying a subset of column data types that you want to see.\n",
    "    - ```cli.get_machine_schema(machine_name, types=['continuous'])```\n",
    "- ```show_hidden```: (default = False) set to True to see the few additional fields that are hidden by default both here and in MA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dict = cli.get_fields_of_machine_type(types[0])\n",
    "type_schema = pd.DataFrame(type_dict)\n",
    "type_schema.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
